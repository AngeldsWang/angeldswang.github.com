<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Brave Matrix]]></title>
  <link href="http://AngeldsWang.github.io/atom.xml" rel="self"/>
  <link href="http://AngeldsWang.github.io/"/>
  <updated>2014-08-11T21:41:27-04:00</updated>
  <id>http://AngeldsWang.github.io/</id>
  <author>
    <name><![CDATA[zhenjun Wang]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Rejection Sampling]]></title>
    <link href="http://AngeldsWang.github.io/blog/20140811/"/>
    <updated>2014-08-11T03:30:00-04:00</updated>
    <id>http://AngeldsWang.github.io/blog/rejection-sampling</id>
    <content type="html"><![CDATA[<p>如何产生符合一定分布的随机变量？对于简单的随机变量，我们往往可以直接获得其概率分布函数<script type="math/tex">F(x)=P(X\leqslant x)</script>。但是对于更多复杂的随机变量来说，获得其概率分布的解析表达式是不可能的。对于这种情况，要产生这样的随机变量就需要另辟蹊径。<strong>Rejection sampling</strong>就是其中最具代表性的一种。下文主要参考了<a href="http://www.columbia.edu/~ks20/4703-Sigman/Monte-Carlo-Sigman.html" title="Karl Sigman's Lecture Notes on Monte Carlo Simulation">Karl Sigman的notes</a>。<!--more--> </p>

<p>Rejection sampling的主要思想是用另一个容易产生的概率分布<script type="math/tex">G</script>，(它的概率密度是<script type="math/tex">g(x)</script>)，来尽可能的逼近所求的概率分布<script type="math/tex">F</script>。形式化出来就是，这两个概率分布密度的比有明确的上界<script type="math/tex">c</script>，即<script type="math/tex">\text{sup}_x\{f(x)/g(x)\}\leqslant c</script>。实际中，<script type="math/tex">c</script>的值尽可能的接近<script type="math/tex">1</script>。下面首先来看如何用Rejection sampling来获得连续随机变量。对于离散随机变量，情况基本类似。</p>

<h3 id="font-colorff5544rejection-samplingfont"><font color="#FF5544">用Rejection sampling算法产生连续随机变量</font></h3>
<table border="2" cellpadding="15px" bordercolor="#FF5544">
<td>
<ol>
<li>生成服从概率分布$G$的随机变量$Y$。</li> <p />
<li>从均匀分布$Uniform(0,1)$采样获得一个随机变量$U$(和$Y$相互独立)。</li> <p />
<li>If $U\leqslant \frac{f(Y)}{cg(Y)}$，then $X=Y$(&#8220;accept&#8221;);<br />
    Otherwise goto step 1 (&#8220;reject&#8221;)。</li> 
</ol>
</td>
</table>
<p><br />
在证明上述算法之前，有以下几点值得我们注意：  </p>

<ul>
  <li><script type="math/tex">f(Y)</script>和<script type="math/tex">g(Y)</script>都是随机变量，因此<script type="math/tex">\frac{f(Y)}{cg(Y)}</script>也是一个随机变量。这一比值和step 2 中的随机变量<script type="math/tex">U</script>是相互独立的。  </li>
  <li>这一比值是以0和1为上下界的，即<script type="math/tex">0\leqslant \frac{f(Y)}{cg(Y)}\leqslant 1</script>。  </li>
  <li>step 1 和 step 2 调用的次数<script type="math/tex">N</script>(也就是成功采样获得一个<script type="math/tex">X</script>所需的迭代次数)本身也是一个服从几何分布的随机变量。其一次试验就发生的概率<script type="math/tex">p=P(U\leqslant \frac{f(Y)}{cg(Y)})</script>，则<script type="math/tex">P(N=n)=(1-p)^{n-1}p, n\geqslant 1</script>。因此迭代次数的期望为<script type="math/tex">E(N)=1/p</script>。  </li>
  <li>最终，我们可以将所期望获得的随机变量<script type="math/tex">X</script>的概率分布<script type="math/tex">F</script>等价于在事件<script type="math/tex">\{U\leqslant \frac{f(Y)}{cg(Y)}\}</script>发生的条件下，随机变量<script type="math/tex">Y</script>的概率分布。<br />
<br />
另外，若以随机变量<script type="math/tex">Y</script>为条件，事件<script type="math/tex">\{U\leqslant \frac{f(Y)}{cg(Y)}\}</script>发生的概率为：<script type="math/tex">P(U\leqslant \frac{f(Y)}{cg(Y)}|Y=y)=\frac{f(y)}{cg(y)}</script>。考虑到<script type="math/tex">Y</script>的概率密度为<script type="math/tex">g(y)</script>，通过去条件化并对<script type="math/tex">Y</script>所有可能的值上进行积分，这样就可以得到<script type="math/tex">p=P(U\leqslant \frac{f(Y)}{cg(Y)})</script>，即：    </li>
</ul>

<script type="math/tex; mode=display">% &lt;![CDATA[
    
\begin{align*}    
p & = \int_{-\infty}^{\infty}\frac{f(y)}{cg(y)}\times g(y)\text{d}y\\
  & = \frac{1}{c}\int_{-\infty}^{\infty}f(y)\text{d}y\\
  & = \frac{1}{c}    
\end{align*}    
 %]]&gt;</script>

<p>因此，算法的迭代次数的期望即为<script type="math/tex">E(N)=c</script>。从这个角度上可以看出，若要使得算法的迭代次数尽可能少，等价于最小化上确界常数<script type="math/tex">c</script>。    </p>

<blockquote>
  <p>算法成功采样一个随机变量<script type="math/tex">X</script>所需的迭代次数的期望即为上确界常数<script type="math/tex">c=\text{sup}_x\{f(x)/g(x)\}</script>。    </p>
</blockquote>

<h3 id="font-colorff5544rejection-samplingfont-1"><font color="#FF5544">Rejection sampling算法证明</font></h3>
<p>由上述说明可知，要证明Rejection sampling算法可行，只需要证明<font color="#F39C12">在给定条件下，随机变量的概率分布即为</font>。    </p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Indian Buffet Process]]></title>
    <link href="http://AngeldsWang.github.io/blog/20140227/"/>
    <updated>2014-02-27T21:55:00-05:00</updated>
    <id>http://AngeldsWang.github.io/blog/indian-buffet-process</id>
    <content type="html"><![CDATA[<p>The Indian buffet process is a <strong>stochastic process</strong> defining a <strong>probability distribution</strong> over <strong>equivalence classes</strong> of sparse binary matrices with a finite number of rows and an unbounded number of columns. (<a href="http://www.jmlr.org/papers/volume12/griffiths11a/griffiths11a.pdf" title="Griffiths and Ghahramani">Griffiths et al., 2011</a>)  上面这段话就是Indian buffet process (IBP)的fathers给出的最简单明确的说明。首先IBP是一个随机过程。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Stochastic Process]]></title>
    <link href="http://AngeldsWang.github.io/blog/20130614/"/>
    <updated>2013-06-14T17:46:00-04:00</updated>
    <id>http://AngeldsWang.github.io/blog/first-post</id>
    <content type="html"><![CDATA[<h2 id="section">概率和测度</h2>

<p>在定义随机过程之前首先要明确两个概念。第一个是<strong>概率空间(probability space)</strong>，而在定义概率空间之前还要明确另一个概念<strong>可测空间(measurable space)</strong>。当然这一切还要从一个叫<strong>“<script type="math/tex">\sigma</script>-代数”</strong>的定义说起。  </p>

<h3 id="sigma-"><script type="math/tex">\sigma</script>-代数</h3>
<p>所谓的<strong>“<script type="math/tex">\sigma</script>-代数”</strong>有时候又叫做<strong><script type="math/tex">\sigma</script>域</strong>，是定义在某个集合<script type="math/tex">X</script>上。所谓的<script type="math/tex">\sigma</script>域就是集合<script type="math/tex">X</script>幂集的子集。形式化出来就是，设<script type="math/tex">X</script>为一个非空集合，满足以下3个条件的集合系(或者叫集类，就是元素也为集合的集合)<script type="math/tex">\cal{F}</script>称为<script type="math/tex">X</script>上的一个<script type="math/tex">\sigma</script>-代数:<br /> <!--more--> </p>

<table>
  <thead>
    <tr>
      <th>Conditions</th>
      <th style="text-align: center">Formulations</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><script type="math/tex">X</script>本身在<script type="math/tex">\cal{F}</script>中：</td>
      <td style="text-align: center"><script type="math/tex">x\in \cal{F}</script></td>
    </tr>
    <tr>
      <td>如果一个集合<script type="math/tex">A</script>在<script type="math/tex">\cal{F}</script>中，它的补集<script type="math/tex">A^c</script>也在<script type="math/tex">\cal{F}</script>中：</td>
      <td style="text-align: center"><script type="math/tex">A\in \cal{F} \Rightarrow A^c\in \cal{F}</script></td>
    </tr>
    <tr>
      <td>如果有若干个集合<script type="math/tex">A_1,\cdots, A_n,\cdots</script>都在<script type="math/tex">\cal{F}</script>中，它们的并集也在<script type="math/tex">\cal{F}</script>中：</td>
      <td style="text-align: center"><script type="math/tex">(\forall n\in\mathbb{N}, A_n\in \cal{F})\Rightarrow \bigcup_{n=1}^{\infty}A_n\in\cal{F}</script></td>
    </tr>
  </tbody>
</table>

<p><br />
简单说来就是<script type="math/tex">\sigma</script>-代数是定义在集合<script type="math/tex">X</script>上一个关于可数并集运算封闭的集合系。其实这里称作集合代数更合适，可能是由于集合代数就算经过再怎么复杂运算后的结果还是逃脱不了集合系这一范围，所以这里叫做集合系或者是集合代数是等价的。</p>

<h3 id="section-1">可测空间和可测函数</h3>
<p>有了以上<script type="math/tex">\sigma</script>-代数的定义，就可以定义可测空间了。所谓的可测空间可以表示为<script type="math/tex">(X,\cal{F})</script>。直观上理解就是这个空间本身是由集合<script type="math/tex">X</script>和集合系<script type="math/tex">\cal{F}</script>共同决定的，而其可测性就是通过集合系<script type="math/tex">\cal{F}</script>具有<script type="math/tex">\sigma</script>-代数关于可数并集运算封闭等性质来体现的。  </p>

<p><strong>可测函数(Measurable function)</strong>是可测空间之间的映射。它的形式化定义是：给定两个可测空间<script type="math/tex">(X,\Sigma)</script>和<script type="math/tex">(Y,T)</script>，存在函数<script type="math/tex">f:X\mapsto Y</script>使得对于任意<script type="math/tex">E\in T</script>的原像都在<script type="math/tex">\Sigma</script>中，则称函数<script type="math/tex">f</script>是可测的：
$$
f^{-1}(E):=\{x\in X|f(x)\in E\}\in \Sigma,  \forall E\in T
$$
由于这里的可测性同样还是由<script type="math/tex">\sigma</script>-代数来保证的，所以这里的可测函数通常写成<script type="math/tex">f:(X,\Sigma)\mapsto (Y,T)</script>。</p>

<h3 id="section-2">测度和测度空间</h3>
<p>更进一步，如果在可测空间上定义一个<strong>测度<script type="math/tex">\mu</script></strong>，则<script type="math/tex">(X,\cal{F},\mu)</script>就组成了一个<strong>测度空间(measure space)</strong>。那么测度又是什么呢？<strong>测度(Measure)</strong>是一个函数，它对一个给定集合的某些子集指定一个数，这个数可以比作大小、体积、概率等等。测度起源于积分的推广。传统的积分是在区间上进行的，后来数学家希望把积分的概念推广到任意集合上，于是就有了测度的概念。测度规定是非负的，定义在集合系<script type="math/tex">\cal{F}</script>上。测度<script type="math/tex">\mu</script>满足：</p>

<ul>
  <li>空集的测度为零： <script type="math/tex">\mu(\emptyset)=0</script>  </li>
  <li>可数可加性，或者叫作<script type="math/tex">\sigma</script>可加性：若<script type="math/tex">E_1,E_2,\cdots,</script>为<script type="math/tex">\cal{F}</script>中可数个两两不相交的集合序列，则所有<script type="math/tex">E_i</script>并集的测度等于每个<script type="math/tex">E_i</script>的测度的总和：
<script type="math/tex">\mu(\bigcup_{i=1}^{\infty}E_i)=\sum_{i=1}^{\infty}\mu(E_i)</script><br />    </li>
</ul>

<h3 id="section-3">概率空间</h3>
<p>很明显，概率满足测度的性质，所以概率就是一种测度，而概率空间就是一个测度空间。不过概率是一种特别的测度，因为概率空间的总测度总为1。概率空间常常用三元组<script type="math/tex">(\Omega,\cal{F}, P)</script>来表示。将测度空间和概率空间对应起来：</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center"> </th>
      <th style="text-align: center">测度空间</th>
      <th style="text-align: left"> </th>
      <th>概率空间</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: center"><script type="math/tex">X</script>是一个非空集合</td>
      <td style="text-align: left"><script type="math/tex">\Rightarrow</script></td>
      <td><script type="math/tex">\Omega</script>是一个非空集合，在概率论中就是样本空间</td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: center"><script type="math/tex">\cal{F}</script>是<script type="math/tex">X</script>幂集的子集</td>
      <td style="text-align: left"><script type="math/tex">\Rightarrow</script></td>
      <td><script type="math/tex">\cal{F}</script>就是样本空间的幂集的子集，在概率论中称作事件集，<script type="math/tex">\cal{F}</script>中的每一个元素就是一个事件</td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: center"><script type="math/tex">\mu</script>是定义在<script type="math/tex">\cal{F}</script>上的测度</td>
      <td style="text-align: left"><script type="math/tex">\Rightarrow</script></td>
      <td><script type="math/tex">P</script>就是定义在事件集的概率函数，<script type="math/tex">P:\cal{F}\mapsto \mathbb{R}</script>,每个事件都被赋一个0，1之间的概率值</td>
    </tr>
  </tbody>
</table>

<p><br /> 
总的说来，以上这些概念之间的依赖关系可以用下图表示：  </p>

<p><img src="http://AngeldsWang.github.io/images/postimgs/dependency.svg" alt="依赖关系图" title="dependency" /></p>

<h2 id="section-4">随机过程</h2>
<p>有了以上的基本定义之后就可以来定义什么是随机过程了。</p>

<p><strong>定义1：(随机过程是一个随机变量的集合)</strong> 给定某个概率空间<script type="math/tex">(\Omega, \cal{F}, P)</script>，随机过程<script type="math/tex">\{X_t\}_{t\in T}</script>是随机变量<script type="math/tex">X_t</script>的集合，<script type="math/tex">X_t</script>取值于某个可测空间<script type="math/tex">(\Xi,\cal{X})</script>中。<script type="math/tex">T</script>是该随机过程的顺序时间下标集。</p>

<p>在初等概率论中一般将随机变量定义成事件到实数的映射，可见随机变量存在函数的性质。那么在高等概率论(也就是随机过程)中，随机变量的函数性质将更加明显，这就是通过可测函数来体现的。因为所谓的随机变量就是由样本空间到实数空间的映射，引入可测性之后，就自然的演变成由样本空间和在其上定义的<script type="math/tex">\sigma</script>-代数所组成的可测空间<script type="math/tex">(\Omega, \cal{F})</script>到另一个可测空间<script type="math/tex">(\Xi,\cal{X})</script>的映射(<script type="math/tex">\Xi</script>和<script type="math/tex">\cal{X}</script>一般取作实数空间<script type="math/tex">\mathbb{R}</script>，和在<script type="math/tex">\mathbb{R}</script>上的<script type="math/tex">\sigma</script>-代数)。这样通过引入可测性就将随机变量的本质给显现出来了，随机变量就是一个可测函数。对应到上述随机过程的定义，对于任意给定的时间<script type="math/tex">t\in T</script>，<script type="math/tex">X_t</script>就是一个<script type="math/tex">\cal{F}/\cal{X}</script>-可测函数：<script type="math/tex">\Omega\mapsto \Xi</script>。更一般的，<script type="math/tex">X_t</script>称作<script type="math/tex">\Xi</script>-valued随机变量，而<script type="math/tex">T</script>中所有时刻的<script type="math/tex">\Xi</script>-valued随机变量的顺序集合就是最终的随机过程了。<script type="math/tex">\Xi</script>就称作该随机过程的状态空间。这时候总体的依赖关系就变成下图所示：</p>

<p><img src="http://AngeldsWang.github.io/images/postimgs/dependencies.svg" alt="依赖关系图_forall" title="dependencies" /></p>

<p>实际上，随机过程还有第二个定义。
<strong>定义2：(随机过程是一个随机函数)</strong> </p>
]]></content>
  </entry>
  
</feed>
